{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO204 Lab 6 - Clustering\n",
    "\n",
    "For this lab we will take a look at how $k$-means and hierarchal clustering works using it for exploratory data analysis and providing preliminary insight into a data set. In addition, we'll also use Elbow Analysis to establish the optimal value for $k$ when clustering data.\n",
    "\n",
    "For code examples, refer to the relevant Sklearn documents, and material in previous lectures and labs. \n",
    "\n",
    "## Part 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(2)\n",
    "X = np.random.standard_normal((50,2))\n",
    "X[:25,0] = X[:25,0]+3\n",
    "X[:25,1] = X[:25,1]-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2. $k$-means clustering of two data sets\n",
    "**Task 1:** Now, use the \"KMeans\" function to cluster data set X. Specify these options: n_clusters=2, n_init=20, and init='random'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to complete ...\n",
    "np.random.seed(4)\n",
    "# km1 = KMeans(...\n",
    "# km1.fit(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:** Use the \"KMeans\" function again to cluster data set X. Specify these options: n_clusters=3, n_init=20, and init='random'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to complete ...\n",
    "np.random.seed(4)\n",
    "# km2 = KMeans(...\n",
    "# km2.fit(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:** Now, produce scatterplots of the data and cluster centres of km1 and km2 by completing the code below:\n",
    "\n",
    "1) Specify s=40, c=km1.labels_, and cmap=plt.cm.prism as part of the scatterplot for the scatterplot of the data\n",
    "\n",
    "2) Specify marker='+', c='k', and linewidth=2 as part of the scatterplot of the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to complete\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(14,5))\n",
    "\n",
    "ax1.set_title('$k$-Means Clustering Results with K=2')\n",
    "\n",
    "ax2.set_title('$k$-Means Clustering Results with K=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment** on which value of $k$ seems more appropriate for clustering the data based on the your analysis of the scatterplots. \n",
    "-  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hierarchal clustering of the two data sets\n",
    "\n",
    "Examine the code below and run it to perform hierarchal clustering, using its different options, of data set X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1, figsize=(15,18))\n",
    "\n",
    "for linkage, cluster, ax in zip([hierarchy.complete(X), hierarchy.average(X), hierarchy.ward(X)], ['c1','c2','c3'],\n",
    "                                [ax1,ax2,ax3]):\n",
    "    cluster = hierarchy.dendrogram(linkage, ax=ax, color_threshold=0)\n",
    "\n",
    "ax1.set_title('Complete Linkage')\n",
    "ax2.set_title('Average Linkage')\n",
    "ax3.set_title('Ward Linkage');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment** on your observations on the differences, if any, on the difference in linkages between the samples and number of clusters found by each linkage method:\n",
    "-  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Finding the optimal vaue for $k$ using Elbow Analysis\n",
    "\n",
    "**Task 5:** Alter the code below to experiment with values of n_samples from 250 to 1000 in increments of 250 in order to find the optimal value for $k$ for each sample set size by viewing the output of the Elbow Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Generating the sample data from make_blobs\n",
    "\n",
    "n_samples=250\n",
    "\n",
    "X, y = make_blobs(n_samples,\n",
    "                  n_features=2,\n",
    "                  centers=4,\n",
    "                  cluster_std=1,\n",
    "                  center_box=(-10.0, 10.0),\n",
    "                  shuffle=True)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c='b', edgecolor='k')\n",
    "plt.title(\"The visualisation of %d observations.\" % (n_samples))\n",
    "plt.xlabel(\"Feature space for the 1st feature\")\n",
    "plt.ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform( X )\n",
    "cluster_range = range( 1, 15 )\n",
    "cluster_errors = []\n",
    "\n",
    "for num_clusters in cluster_range:\n",
    "    clusters = KMeans( num_clusters )\n",
    "    clusters.fit( X_scaled )\n",
    "    cluster_errors.append( clusters.inertia_ )\n",
    "    \n",
    "plt.figure(figsize=(12,6))\n",
    "clusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors } )\n",
    "print(clusters_df[0:10])\n",
    "plt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Cluster errors (variance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **Comment** on your observations on how the shape of the elbow is affected as the number and distribution of samples increases. \n",
    "\n",
    "2) **Can** you make any general comments about how effective Elbow Analysis is for determining the value of $k$?\n",
    "\n",
    "-  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
